{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* resutl:  <title>크롤링 연습사이트 01</title>\n",
      "* result 타입 :  <class 'bs4.element.Tag'>\n",
      "* 태그 내용만 갖고오기 :  크롤링 연습사이트 01\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/01/') # 서버에 요청\n",
    "source = response.text \n",
    "soup = BeautifulSoup(source, 'html.parser') # bs class는 feature 인자값으로 str타입을 받아들임\n",
    "\n",
    "result = soup.select_one('title')\n",
    "\n",
    "print('* resutl: ', result) # title 태그\n",
    "print('* result 타입 : ', type(result)) # result는 태그를 갖고온 객체임을 알 수 있음\n",
    "print('* 태그 내용만 갖고오기 : ', result.text) # 갖고온 태그를 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result : <title id=\"browserTitleArea\">네이버 뉴스</title>\n",
      "태그 내용만 갖고오기 : 네이버 뉴스\n"
     ]
    }
   ],
   "source": [
    "# 네이버 뉴스 페이지 response 받아오기\n",
    "response = requests.get(\"https://news.naver.com\")\n",
    "source = response.text\n",
    "soup = BeautifulSoup(source, 'html.parser')\n",
    "\n",
    "result = soup.select_one('title')\n",
    "\n",
    "print('result :', result)\n",
    "print('태그 내용만 갖고오기 :', result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get vs post\n",
    "- get : (데이터 요청) 서버에 게시글을 보기만 하는 것\n",
    "- post : (데이터 전송) 게시물을 작성하는 등 서버의 상태를 변경하는 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [418]>\n",
      "<Response [418]>\n",
      "<Response [418]>\n"
     ]
    }
   ],
   "source": [
    "# response 응답 확인\n",
    "for i in [1,2,3]:\n",
    "    url = f'https://search.shopping.naver.com/search/all?adQuery=%EC%83%B4%ED%91%B8&origQuery=%EC%83%B4%ED%91%B8&pagingSize=10&productSet=total&query=%EC%83%B4%ED%91%B8&sort=rel&timestamp=&viewType=list$page={i}'\n",
    "\n",
    "    print(requests.get(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup\n",
    "\n",
    "- 원하는 태그 갖고 오는 방법\n",
    "\n",
    "1. html 소스를 갖고온다 : source = requests.get(url).text\n",
    "\n",
    "2. BeautifulSoup으로 html을 구조화 하고 분석한다 : BeautifulSoup(source, ‘html.parser’)\n",
    "- html.parser : html 포맷의 문서를 parsing (구조화하고 분석)\n",
    "- parsing하는 이유 : html을 분석하여 원하는 태그를 갖고오기 위함\n",
    "\n",
    "3. 특정 태그를 선택하여 원하는 데이터를 갖고 온다.\n",
    "- soup.select_one(‘css 선택자’) / soup.select(‘css 선택자’)\n",
    "- soup.find(‘tag_name’) / soup.find_all(‘tag_name’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select로 데이터 갖고 오기\n",
    "\n",
    "- 종류\n",
    "1. .select(‘css 선택자’)\n",
    "- css선택자를 파라미터로 받음\n",
    "- 모든 일치하는 태그를 list형식으로 return >> 인덱싱, 슬라이싱 가능\n",
    "- html.select(), tag.select() 둘 다 가능\n",
    "\n",
    "2. .select_one(‘css 선택자’)\n",
    "- 매칭되는 태그 중 가장 첫 번째 태그를 갖고 옴\n",
    "- list에 넣지 않고 바로 return해줌\n",
    "- html.select_one(), tag.select_one() 둘 다 가능\n",
    "\n",
    "- css 선택자로 태그 갖고 오기\n",
    "1. 태그 셀렉터 : soup.select(‘tag_name’) / soup.select_one(‘tag_name’)\n",
    "2. ID 셀렉터 : soup.select(‘#id_name’) / soup.select_one(‘#id_name’)\n",
    "3. Class 셀렉터 : soup.select(‘.class_name’) / soup.select_one(‘.class_name’)\n",
    "4. 속성 셀렉터 : soup.select(‘tag[속성=‘속성값‘]’) / soup.select_one(‘tag[속성=‘속성값‘]’)\n",
    "5. 후손 셀렉터 : soup.select(‘tag tag2’) / soup.select_one(‘tag tag2’)\n",
    "6. 자식 셀렉터 : soup.select(‘tag > tag2’) / soup.select_one(‘tag > tag2’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " p 태그 개수 : 1\n",
      "p_tags.text >> \n",
      "    이탈리아 요리의 시작은 기원전 4세기로 거슬러 올라갈 수 있다. 대항해시대를 거치면서 아메리카 대륙에서 감자·토마토·후추·옥수수 등이 유입되어 그 종류와 풍미가 다양해졌고 현대에 이르러서는 피자와 파스타 등 많은 이탈리아 요리가 널리 퍼지게 되었다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'전통적인 요리법이나 양식은 상당한 차이가 있지만, 이탈리아 요리는 다른 국가의 요리 문화에서 다양한 영감을 줄 만큼 다양하고 혁신적인 것으로 평가되고 있다. 각 지방마다 고유의 특색이 있어 그 양식도 다양하지만 크게 북부와 남부로 나눌 수 있다. 다른 나라와 국경을 맞대고 있던 북부 지방은 산업화되어 경제적으로 풍족하고 농업이 발달해 쌀이 풍부해 유제품이 다양한 반면 경제적으로 침체되었던 남부 지방은 올리브와 토마토, 모차렐라 치즈가 유명하고 특별히 해산물을 활용한 요리가 많다. 식재료와 치즈 등의 차이는 파스타의 종류와 소스와 수프 등도 다름을 의미한다.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p 태그 가져오기\n",
    "p_tags = soup.select_one('p')\n",
    "\n",
    "print(' p 태그 개수 :',len(p_tags))\n",
    "# strip() : 공백 제거 함수\n",
    "p_tags.text.strip()\n",
    "\n",
    "# 두번째 p를 select.one으로 가져오기\n",
    "p_tags = soup.select_one('p#cook')\n",
    "p_tags.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이탈리아 요리의 시작은 기원전 4세기로 거슬러 올라갈 수 있다. 대항해시대를 거치면서 아메리카 대륙에서 감자·토마토·후추·옥수수 등이 유입되어 그 종류와 풍미가 다양해졌고 현대에 이르러서는 피자와 파스타 등 많은 이탈리아 요리가 널리 퍼지게 되었다.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p 태그 안에 text 가져오기\n",
    "p_tags[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[<table border=\"1\">\n",
      "<thead>\n",
      "<tr>\n",
      "<th class=\"tablehead\">이름</th>\n",
      "<th class=\"tablehead\">나이</th>\n",
      "</tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr>\n",
      "<td>이몽룡</td>\n",
      "<td>34</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>홍길동</td>\n",
      "<td>23</td>\n",
      "</tr>\n",
      "</tbody>\n",
      "</table>]\n"
     ]
    }
   ],
   "source": [
    "# 1. tabele 태그 가져오기\n",
    "table_tags = soup.select('table')\n",
    "print(len(table_tags))\n",
    "print(table_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tr_tags : [<tr>\n",
      "<th class=\"tablehead\">이름</th>\n",
      "<th class=\"tablehead\">나이</th>\n",
      "</tr>, <tr>\n",
      "<td>이몽룡</td>\n",
      "<td>34</td>\n",
      "</tr>, <tr>\n",
      "<td>홍길동</td>\n",
      "<td>23</td>\n",
      "</tr>]\n",
      "tr tag :  \n",
      "이름\n",
      "나이\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. tag에서 다시 tag 가져오기\n",
    "tr_tags = table_tags[0].select('tr')\n",
    "\n",
    "print(len(tr_tags))\n",
    "print('tr_tags :',tr_tags)\n",
    "\n",
    "# 안에 있는 값 가져오기\n",
    "tr_tags[2].text.strip().split('\\n')\n",
    "\n",
    "tr_tag = soup.select_one('table tr').text\n",
    "print('tr tag : ',tr_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번쨰리스트\n",
      "두번째리스트\n",
      "세번째리스트\n",
      "네번째리스트\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://crawlingstudy-dd3c9.web.app/02/\")\n",
    "source = response.text\n",
    "soup = BeautifulSoup(source, 'html.parser')\n",
    "\n",
    "for i in range(4):\n",
    "    print(soup.select('div li')[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "온세상이 떨릴듯\n",
      "두근거리고 익숙한 듯 편안해\n",
      "네가 느껴져\n",
      "오래된 친구같아\n"
     ]
    }
   ],
   "source": [
    "p_tags = soup.select('#winter p')\n",
    "\n",
    "for i in range(len(p_tags)):\n",
    "    print(p_tags[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두번째리스트\n"
     ]
    }
   ],
   "source": [
    "class_bold_list = soup.select_one('.bold .blue')\n",
    "print(class_bold_list.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://naver.com\n",
      "http://naver.com\n",
      "{'href': 'http://naver.com', 'target': '_blank'}\n"
     ]
    }
   ],
   "source": [
    "# href의 속성값이 com으로 끝나는 태그 가져오기\n",
    "href_com_list = soup.select('a[href$=\".com\"]')\n",
    "href_com = soup.select_one('a[href$=\".com\"]')\n",
    "\n",
    "# 속성값 가져오기 2가지 방법\n",
    "print(href_com.get('href'))\n",
    "print(href_com.attrs['href'])\n",
    "\n",
    "# 딕셔너리 형태로 가져오기 때문에 ['속성값'] 필요\n",
    "print(href_com.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://naver.com\" target=\"_blank\">네이버</a>\n",
      "--------------------------------------------------\n",
      "<a href=\"http://naver.com\" target=\"_blank\">네이버</a>\n"
     ]
    }
   ],
   "source": [
    "# targetdl _black인 태그 가져오기\n",
    "target_blank_list = soup.select_one('a[target=\"_blank\"]')\n",
    "target_blank = soup.select_one('a[target=\"_blank\"]')\n",
    "\n",
    "print(target_blank_list)\n",
    "print('-'*50)\n",
    "print(target_blank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 후손 셀렉터로 태그 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>온세상이 떨릴듯</p>, <p class=\"blue\">두근거리고 <span>익숙한 듯 편안해</span></p>, <p>네가 느껴져</p>, <p class=\"blue\">오래된 친구같아</p>]\n",
      "<p>온세상이 떨릴듯</p>\n"
     ]
    }
   ],
   "source": [
    "# id가 winter인 div 태그의 후손 p 태그 갖고오기\n",
    "p_tag_list = soup.select('div#winter p')\n",
    "p_tag = soup.select_one('div#winter p')\n",
    "\n",
    "print(p_tag_list)\n",
    "print(p_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자식 셀렉터로 태그 가져오기\n",
    "- 직계 하나만 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>온세상이 떨릴듯</p>, <p class=\"blue\">두근거리고 <span>익숙한 듯 편안해</span></p>]\n"
     ]
    }
   ],
   "source": [
    "# id가 winter인 div태그의 자식 p 태그 가져오기\n",
    "child_p_list = soup.select('div#winter > p')\n",
    "child_p = soup.select_one('div#winter > p')\n",
    "\n",
    "print(child_p_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
